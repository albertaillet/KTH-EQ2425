{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href='https://colab.research.google.com/github/albertaillet/KTH-EQ2425/blob/master/project3/main.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsLb2bLCuIqY"
      },
      "outputs": [],
      "source": [
        "%pip install wandb --quiet # if using colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkOe61L2uL9d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.random import set_seed\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical, set_random_seed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# for type hinting\n",
        "from typing import List\n",
        "from numpy import ndarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt0dIfJ92Ry-"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VfouJcosXgM"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld4ydEuJ4TQq"
      },
      "outputs": [],
      "source": [
        "def create_config(\n",
        "    input_shape: tuple=(32, 32, 3),\n",
        "    num_classes: int=10,\n",
        "    activation: str='relu',\n",
        "    output_activation: str='softmax',\n",
        "    conv_kernel_sizes: List[tuple]=[(5, 5), (3, 3), (3, 3)],\n",
        "    conv_strides: List[int]=[1, 1, 1],\n",
        "    conv_filters: List[int]=[24, 48, 96],\n",
        "    conv_activate: List[bool]=[True, True, False],\n",
        "    pool_kernel_sizes: List[tuple]=[(2, 2), (2, 2), (2, 2)],\n",
        "    pool_strides: List[int]=[2, 2, 2],\n",
        "    fully_connected_sizes: List[int]=[512],\n",
        "    dropout: bool=False,\n",
        "    dropout_rate: float=0.3,\n",
        "    batch_normalization: bool=False,\n",
        "    batch_size: int=64,\n",
        "    learning_rate: float=1e-3,\n",
        "    model_name: str='cifar10_model',\n",
        "    data_shuffling: bool=False,\n",
        "    epochs: int=300,\n",
        "    optimizer: str='sgd',\n",
        "    augmentation: bool=False,\n",
        "    augmentation_flip: str='horizontal_and_vertical',\n",
        "    augmentation_rotation: float=0.1,\n",
        "    augmentation_zoom: float=0.1,\n",
        "    augmentation_brightness: float=0.1,\n",
        "    monitor: str='val_loss',\n",
        "    patience: int=15,\n",
        "    seed: int=1,\n",
        "    sweep: bool=False,\n",
        ") -> dict:\n",
        "    '''\n",
        "    Creates a dictionary of hyperparameters for the model.\n",
        "    :param input_shape: shape of the input images\n",
        "    :param num_classes: number of classes in the dataset\n",
        "    :param activation: activation function to use on the convolutional layers and the fully connected layers\n",
        "    :param output_activation: activation function to use on the output layer\n",
        "    :param conv_kernel_sizes: list of kernel sizes for the convolutional layers\n",
        "    :param conv_strides: list of strides for the convolutional layers\n",
        "    :param conv_filters: list of number of filters for the convolutional layers\n",
        "    :param conv_activate: list of booleans indicating whether to use the activation function on the convolutional layers\n",
        "    :param pool_kernel_sizes: list of kernel sizes for the pooling layers\n",
        "    :param pool_strides: list of strides for the pooling layers\n",
        "    :param fully_connected_sizes: list of sizes for the fully connected layers\n",
        "    :param dropout: whether to use dropout\n",
        "    :param dropout_rate: dropout rate\n",
        "    :param batch_normalization: whether to use batch normalization\n",
        "    :param batch_size: batch size\n",
        "    :param learning_rate: learning rate\n",
        "    :param model_name: name of the model\n",
        "    :param data_shuffling: whether to shuffle the data\n",
        "    :param epochs: number of epochs\n",
        "    :param optimizer: optimizer to use\n",
        "    :param augmentation: whether to use data augmentation\n",
        "    :param augmentation_flip: whether to flip the images horizontally, vertically or both\n",
        "    :param augmentation_rotation: rotation range for data augmentation\n",
        "    :param augmentation_zoom: zoom range for data augmentation\n",
        "    :param augmentation_brightness: brightness range for data augmentation\n",
        "    :param monitor: metrics to monitor\n",
        "    :param patience: patience for early stopping\n",
        "    :param seed: seed for the random number generators\n",
        "    :param sweep: whether to create a sweep config or a normal config\n",
        "    :return: config of hyperparameters or a sweep config\n",
        "    '''\n",
        "    if sweep:\n",
        "        del sweep\n",
        "        return {\n",
        "            k:(\n",
        "                v if isinstance(v, dict) else {'value': v}\n",
        "            ) \n",
        "            for k,v in locals().items()\n",
        "        }\n",
        "    else:\n",
        "        del sweep\n",
        "        return locals()\n",
        "\n",
        "def create_model(\n",
        "    input_shape: tuple,\n",
        "    num_classes: int,\n",
        "    activation: str,\n",
        "    output_activation: str,\n",
        "    conv_kernel_sizes: List[tuple],\n",
        "    conv_strides: List[int],\n",
        "    conv_filters: List[int],\n",
        "    conv_activate: List[bool],\n",
        "    pool_kernel_sizes: List[tuple],\n",
        "    pool_strides: List[int],\n",
        "    fully_connected_sizes: List[int],\n",
        "    dropout: bool,\n",
        "    dropout_rate: float,\n",
        "    batch_normalization: bool,\n",
        "    batch_size: int,\n",
        "    learning_rate: float,\n",
        "    model_name: str,\n",
        "    optimizer: str,\n",
        "    augmentation: bool,\n",
        "    augmentation_flip: str,\n",
        "    augmentation_rotation: float,\n",
        "    augmentation_zoom: float,\n",
        "    augmentation_brightness: float,\n",
        "    seed: int,\n",
        "    **kwargs,\n",
        ") -> models.Model:\n",
        "    '''\n",
        "    Creates and trains a model on the CIFAR10 dataset.\n",
        "    :param input_shape: shape of the input images\n",
        "    :param num_classes: number of classes in the dataset\n",
        "    :param activation: activation function to use on the convolutional layers and the fully connected layers\n",
        "    :param output_activation: activation function to use on the output layer\n",
        "    :param conv_kernel_sizes: list of kernel sizes for the convolutional layers\n",
        "    :param conv_strides: list of strides for the convolutional layers\n",
        "    :param conv_filters: list of number of filters for the convolutional layers\n",
        "    :param conv_activate: list of booleans indicating whether to use the activation function on the convolutional layers\n",
        "    :param pool_kernel_sizes: list of kernel sizes for the pooling layers\n",
        "    :param pool_strides: list of strides for the pooling layers\n",
        "    :param fully_connected_sizes: list of sizes for the fully connected layers\n",
        "    :param dropout: whether to use dropout\n",
        "    :param dropout_rate: dropout rate\n",
        "    :param batch_normalization: whether to use batch normalization\n",
        "    :param batch_size: batch size\n",
        "    :param learning_rate: learning rate\n",
        "    :param model_name: name of the model\n",
        "    :param optimizer: optimizer to use\n",
        "    :param augmentation: whether to use data augmentation\n",
        "    :param seed: seed for the random number generators\n",
        "    :return: created model\n",
        "    '''\n",
        "    # set random seed for reproducibility\n",
        "    set_seed(seed)\n",
        "    set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Create model\n",
        "    model = models.Sequential(name=model_name)\n",
        "    model.add(layers.Input(shape=input_shape))\n",
        "\n",
        "    # Normalize the pixel values to the range of [-0.5, 0.5].\n",
        "    model.add(layers.Lambda(lambda x: (x / 255.0) - 0.5, name='normalize'))\n",
        "\n",
        "    # Add data augmentation layers\n",
        "    if augmentation:\n",
        "        model.add(layers.RandomFlip('horizontal_and_vertical'))\n",
        "        model.add(layers.RandomRotation(0.1))\n",
        "        model.add(layers.RandomZoom(0.1))\n",
        "        model.add(layers.RandomBrightness(0.1))\n",
        "\n",
        "\n",
        "    names = [[f'conv_{i}', f'pool_{i}'] for i in range(1, len(conv_kernel_sizes)+1)]\n",
        "    # Convolutional layers.\n",
        "    for kernel_size, stride, filters, activate, pool_kernel_size, pool_stride, (conv_name, pool_name) in zip(\n",
        "        conv_kernel_sizes,\n",
        "        conv_strides,\n",
        "        conv_filters,\n",
        "        conv_activate,\n",
        "        pool_kernel_sizes,\n",
        "        pool_strides,\n",
        "        names,\n",
        "    ):\n",
        "        # Add convolutional layer\n",
        "        model.add(\n",
        "            layers.Conv2D(\n",
        "                kernel_size=kernel_size,\n",
        "                strides=stride,\n",
        "                padding='valid',\n",
        "                filters=filters,\n",
        "                name=conv_name,\n",
        "            )\n",
        "        )\n",
        "        if activate:\n",
        "            # Add activation\n",
        "            model.add(layers.Activation(activation))\n",
        "\n",
        "            # Add batch normalization\n",
        "            if batch_normalization:\n",
        "                model.add(layers.BatchNormalization())\n",
        "        \n",
        "        # Add pooling\n",
        "        model.add(\n",
        "            layers.MaxPooling2D(\n",
        "                pool_size=pool_kernel_size, \n",
        "                strides=pool_stride, \n",
        "                name=pool_name,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    # Flatten the output of the convolutional layers.\n",
        "    model.add(layers.Flatten(name='flatten'))\n",
        "\n",
        "    names = [f'fc_{i}' for i in range(1, len(fully_connected_sizes)+1)]\n",
        "    # Fully connected layers.\n",
        "    for size, name in zip(fully_connected_sizes, names):\n",
        "        model.add(layers.Dense(size, name=name))\n",
        "        model.add(layers.Activation(activation))\n",
        "        if dropout:\n",
        "            model.add(layers.Dropout(dropout_rate))\n",
        "        if batch_normalization:\n",
        "            model.add(layers.BatchNormalization())\n",
        "    \n",
        "    # Output layer\n",
        "    model.add(layers.Dense(num_classes, activation=output_activation, name=f'fc_{len(fully_connected_sizes)+1}'))\n",
        "    \n",
        "    # Compile the model.\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "def train_function(init=True):\n",
        "    if init:\n",
        "        wandb.init()\n",
        "    \n",
        "    model = create_model(**wandb.config)\n",
        "\n",
        "    wandb_callback = WandbCallback(monitor=wandb.config['monitor'], mode='auto')\n",
        "    early_stopping = EarlyStopping(monitor=wandb.config['monitor'], patience=wandb.config['patience'])    \n",
        "    \n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=wandb.config['epochs'],\n",
        "        batch_size=wandb.config['batch_size'],\n",
        "        validation_data=(X_test, y_test),\n",
        "        shuffle=wandb.config['data_shuffling'],\n",
        "        callbacks=[\n",
        "            wandb_callback,\n",
        "            early_stopping\n",
        "        ],\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Single Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8hgmHfR4TQp"
      },
      "outputs": [],
      "source": [
        "partial_config = {\n",
        "    'learning_rate': 1e-3,\n",
        "    'epochs': 1,\n",
        "    'batch_size': 64,\n",
        "    'optimizer': 'sgd',\n",
        "    'augmentation': True,\n",
        "}\n",
        "wandb.init(\n",
        "    project='project3', \n",
        "    entity='eq2425_2022p3_aillet_bonato',\n",
        "    config = create_config(**partial_config),\n",
        ")\n",
        "train_function(init=False)\n",
        "wandb.run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjEw-UqNXnDl"
      },
      "source": [
        "## Sweeping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq-jC4f2XnDp"
      },
      "outputs": [],
      "source": [
        "partial_config = {\n",
        "    'epochs': 300,\n",
        "    'seed': 1,\n",
        "    'optimizer': 'sgd',\n",
        "    'conv_filters': [64, 128, 256],\n",
        "    'fully_connected_sizes': [512],\n",
        "    'conv_kernel_sizes': [(5, 5), (3, 3), (3, 3)],\n",
        "    'activation': 'relu',\n",
        "    'dropout' : True,\n",
        "    'batch_normalization' : True,\n",
        "    'batch_size': {\n",
        "        'values': [\n",
        "          64,\n",
        "          256\n",
        "        ]\n",
        "    },\n",
        "    'augmentation': {\n",
        "        'values': [\n",
        "            True,\n",
        "            False\n",
        "        ]\n",
        "    },\n",
        "    'learning_rate': {\n",
        "        'values': [\n",
        "            1e-3,\n",
        "            0.1\n",
        "        ]\n",
        "    },\n",
        "    'data_shuffling': {\n",
        "        'values': [\n",
        "            True,\n",
        "            False\n",
        "        ]\n",
        "    },\n",
        "}\n",
        "sweep_config = {\n",
        "    'name': 'sweep_augmentation',\n",
        "    'method': 'grid',\n",
        "    'parameters': create_config(**partial_config, sweep=True)\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project='project3', entity='eq2425_2022p3_aillet_bonato')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLqlEUBsXnDq"
      },
      "outputs": [],
      "source": [
        "# start the sweep\n",
        "wandb.agent(sweep_id, function=train_function)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('tf-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "997f2eb5bf27194238f7c2d0fafc406765e99f44a8da62f11c5168f8901f17e1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

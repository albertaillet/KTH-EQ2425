{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertaillet/KTH-EQ2425/blob/master/project3/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsLb2bLCuIqY"
      },
      "outputs": [],
      "source": [
        "# %pip install wandb --quiet # if using colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UkOe61L2uL9d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.random import set_seed\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# for type hinting\n",
        "from typing import List\n",
        "from numpy import ndarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yt0dIfJ92Ry-"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_VfouJcosXgM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimonebonato\u001b[0m (\u001b[33meq2425_2022p3_aillet_bonato\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "partial_config = {\n",
        "        \"learning_rate\": 1e-3,\n",
        "        \"epochs\": 1,\n",
        "        \"batch_size\": 64,\n",
        "        \"dropout\": False,\n",
        "        \"batch_normalization\": False,\n",
        "        \"data_shuffling\": False,\n",
        "        \"seed\": 1,\n",
        "        \"optimizer\": \"sgd\",\n",
        "        # \"conv_filters\": [64,128,256]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_useless_keys(d: dict, to_remove: List[str]) -> dict:\n",
        "    \"\"\"Remove keys that are not used in the model\"\"\"\n",
        "    for key in to_remove:\n",
        "        d.pop(key, None)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ld4ydEuJ4TQq"
      },
      "outputs": [],
      "source": [
        "def create_and_train_model(\n",
        "    input_shape: tuple=(32, 32, 3),\n",
        "    num_classes: int=10,\n",
        "    activation: str=\"relu\",\n",
        "    output_activation: str='softmax',\n",
        "    conv_kernel_sizes: List[tuple]=[(5, 5), (3, 3), (3, 3)],\n",
        "    conv_strides: List[int]=[1, 1, 1],\n",
        "    conv_filters: List[int]=[24, 48, 96],\n",
        "    conv_activate: List[bool]=[True, True, False],\n",
        "    pool_kernel_sizes: List[tuple]=[(2, 2), (2, 2), (2, 2)],\n",
        "    pool_strides: List[int]=[2, 2, 2],\n",
        "    fully_connected_sizes: List[int]=[512],\n",
        "    dropout: bool=False,\n",
        "    dropout_rate: float=0.3,\n",
        "    batch_normalization: bool=False,\n",
        "    batch_size: int=64,\n",
        "    learning_rate: float=1e-3,\n",
        "    model_name: str=\"cifar10_model\",\n",
        "    data_shuffling: bool=False,\n",
        "    epochs: int=300,\n",
        "    optimizer: str=\"sgd\",\n",
        "    seed: int=1,\n",
        ") -> models.Model:\n",
        "    \"\"\"\n",
        "    Creates and trains a model on the CIFAR10 dataset.\n",
        "    :param input_shape: shape of the input images\n",
        "    :param num_classes: number of classes in the dataset\n",
        "    :param activation: activation function to use on the convolutional layers and the fully connected layers\n",
        "    :param output_activation: activation function to use on the output layer\n",
        "    :param conv_kernel_sizes: list of kernel sizes for the convolutional layers\n",
        "    :param conv_strides: list of strides for the convolutional layers\n",
        "    :param conv_filters: list of number of filters for the convolutional layers\n",
        "    :param conv_activate: list of booleans indicating whether to use the activation function on the convolutional layers\n",
        "    :param pool_kernel_sizes: list of kernel sizes for the pooling layers\n",
        "    :param pool_strides: list of strides for the pooling layers\n",
        "    :param fully_connected_sizes: list of sizes for the fully connected layers\n",
        "    :param dropout: whether to use dropout\n",
        "    :param dropout_rate: dropout rate\n",
        "    :param batch_normalization: whether to use batch normalization\n",
        "    :param batch_size: batch size\n",
        "    :param learning_rate: learning rate\n",
        "    :param model_name: name of the model\n",
        "    :param data_shuffling: whether to shuffle the data\n",
        "    :param epochs: number of epochs\n",
        "    :param seed: seed for the random number generators\n",
        "    \"\"\"\n",
        "    # set random seed for reproducibility\n",
        "    set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "    # Create model\n",
        "    model = models.Sequential(name=model_name)\n",
        "    model.add(layers.Input(shape=input_shape))\n",
        "\n",
        "    # Normalize the pixel values to the range of [-0.5, 0.5].\n",
        "    model.add(layers.Lambda(lambda x: (x / 255.0) - 0.5, name=\"normalize\"))\n",
        "\n",
        "    names = [[f\"conv_{i}\", f\"pool_{i}\"] for i in range(1, len(conv_kernel_sizes)+1)]\n",
        "    # Convolutional layers.\n",
        "    for kernel_size, stride, filters, activate, pool_kernel_size, pool_stride, (conv_name, pool_name)in zip(\n",
        "        conv_kernel_sizes,\n",
        "        conv_strides,\n",
        "        conv_filters,\n",
        "        conv_activate,\n",
        "        pool_kernel_sizes,\n",
        "        pool_strides,\n",
        "        names,\n",
        "    ):\n",
        "        model.add(\n",
        "            layers.Conv2D(\n",
        "                kernel_size=kernel_size,\n",
        "                strides=stride,\n",
        "                padding=\"valid\",\n",
        "                filters=filters,\n",
        "                activation=activation if activate else None,\n",
        "                name=conv_name,\n",
        "            )\n",
        "        )\n",
        "        if activate and batch_normalization:\n",
        "            model.add(layers.BatchNormalization())\n",
        "        model.add(\n",
        "            layers.MaxPooling2D(\n",
        "                pool_size=pool_kernel_size, \n",
        "                strides=pool_stride, \n",
        "                name=pool_name,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    # Flatten the output of the convolutional layers.\n",
        "    model.add(layers.Flatten(name=\"flatten\"))\n",
        "\n",
        "    names = [f\"fc_{i}\" for i in range(1, len(fully_connected_sizes)+1)]\n",
        "    # Fully connected layers.\n",
        "    for size, name in zip(fully_connected_sizes, names):\n",
        "        model.add(layers.Dense(size, activation=activation, name=name))\n",
        "        if dropout:\n",
        "            model.add(layers.Dropout(dropout_rate))\n",
        "        if batch_normalization:\n",
        "            model.add(layers.BatchNormalization())\n",
        "    \n",
        "    # Output layer\n",
        "    model.add(layers.Dense(num_classes, activation=output_activation, name=f\"fc_{len(fully_connected_sizes)+1}\"))\n",
        "    \n",
        "    # Compile the model.\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    \n",
        "    return model, remove_useless_keys(locals(), ['model', 'model_name', 'names', 'name', 'pool_name', 'conv_name', 'pool_size', 'size', 'stride', 'pool_stride', 'activate'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRvZsqEO4TQs"
      },
      "outputs": [],
      "source": [
        "model, full_config = create_and_train_model(**partial_config)\n",
        "# model = create_and_train_model(**wandb.config)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8hgmHfR4TQp"
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "    project=\"project3\", \n",
        "    entity=\"eq2425_2022p3_aillet_bonato\",\n",
        "    config = full_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMfp_mnR5c0s"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=wandb.config['epochs'],\n",
        "    batch_size=wandb.config['batch_size'],\n",
        "    validation_data=(X_test, y_test),\n",
        "    shuffle=wandb.config['data_shuffling'],\n",
        "    callbacks=[WandbCallback()],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# log the recall rate\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "recall = np.sum(y_test.argmax(axis=1) == preds.argmax(axis=1)) / len(y_test)\n",
        "\n",
        "wandb.log({\"recall\": recall})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oUekt0aFh3q"
      },
      "outputs": [],
      "source": [
        "wandb.run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sweeping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sweep(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "        model, _ = create_and_train_model(**wandb.config)\n",
        "        model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=wandb.config['epochs'],\n",
        "        batch_size=wandb.config['batch_size'],\n",
        "        validation_data=(X_test, y_test),\n",
        "        shuffle=wandb.config['data_shuffling'],\n",
        "        callbacks=[WandbCallback()],\n",
        "        )\n",
        "        preds = model.predict(X_test)\n",
        "        recall = np.sum(y_test.argmax(axis=1) == preds.argmax(axis=1)) / len(y_test)\n",
        "        wandb.log({\"recall\": recall})\n",
        "\n",
        "def add_to_sweep(sweep_config, d):\n",
        "    for k, v in d.items():\n",
        "        if k not in sweep_config['parameters']:\n",
        "            sweep_config['parameters'][k] = {'value': v}\n",
        "    return sweep_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'method': 'grid', 'parameters': {'conv_filters': {'values': [[24, 48, 96], [64, 128, 256]]}, 'learning_rate': {'value': 0.001}, 'epochs': {'value': 1}, 'batch_size': {'value': 64}, 'dropout': {'value': False}, 'batch_normalization': {'value': False}, 'data_shuffling': {'value': False}, 'seed': {'value': 1}, 'optimizer': {'value': 'sgd'}}}\n",
            "Create sweep with ID: i7ytjfap\n",
            "Sweep URL: https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/sweeps/i7ytjfap\n"
          ]
        }
      ],
      "source": [
        "sweep_config = {\n",
        "    'name': 'sweep_',\n",
        "    'method': 'grid',\n",
        "    }\n",
        "\n",
        "# set up variables you don't want to sweep over, but that will be added to the sweep_config\n",
        "partial_config = {\n",
        "        \"learning_rate\": 1e-3,\n",
        "        \"epochs\": 300,\n",
        "        \"batch_size\": 64,\n",
        "        \"dropout\": False,\n",
        "        \"batch_normalization\": False,\n",
        "        \"data_shuffling\": False,\n",
        "        \"seed\": 1,\n",
        "        \"optimizer\": \"sgd\",\n",
        "        # \"conv_filters\": [64,128,256]\n",
        "    }\n",
        "\n",
        "# dictionary containig the values to sweep over\n",
        "parameters_dict = {\n",
        "    'conv_filters': {\n",
        "        'values': [\n",
        "            [24, 48, 96],\n",
        "            [64, 128, 256],\n",
        "        ]\n",
        "        },\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "sweep_config = add_to_sweep(sweep_config, partial_config)\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"project3\", entity=\"eq2425_2022p3_aillet_bonato\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cg4ma7og with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [24, 48, 96]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_shuffling: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 1\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\simon\\PycharmProjects\\AnalysisSearchVD\\KTH-EQ2425\\project3\\wandb\\run-20221004_143421-cg4ma7og</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/runs/cg4ma7og\" target=\"_blank\">fallen-sweep-1</a></strong> to <a href=\"https://wandb.ai/eq2425_2022p3_aillet_bonato/project3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/sweeps/i7ytjfap\" target=\"_blank\">https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/sweeps/i7ytjfap</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\simon\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "782/782 [==============================] - ETA: 0s - loss: 2.1103 - accuracy: 0.2386"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: c:\\Users\\simon\\PycharmProjects\\AnalysisSearchVD\\KTH-EQ2425\\project3\\wandb\\run-20221004_143421-cg4ma7og\\files\\model-best\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: c:\\Users\\simon\\PycharmProjects\\AnalysisSearchVD\\KTH-EQ2425\\project3\\wandb\\run-20221004_143421-cg4ma7og\\files\\model-best\\assets\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (c:\\Users\\simon\\PycharmProjects\\AnalysisSearchVD\\KTH-EQ2425\\project3\\wandb\\run-20221004_143421-cg4ma7og\\files\\model-best)... Done. 0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 88s 111ms/step - loss: 2.1103 - accuracy: 0.2386 - val_loss: 1.9004 - val_accuracy: 0.3159\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.0038</td></tr><tr><td>accuracy</td><td>0.23858</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.90039</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.11034</td></tr><tr><td>recall</td><td>0.3159</td></tr><tr><td>val_accuracy</td><td>0.3159</td></tr><tr><td>val_loss</td><td>1.90039</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">fallen-sweep-1</strong>: <a href=\"https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/runs/cg4ma7og\" target=\"_blank\">https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/runs/cg4ma7og</a><br/>Synced 6 W&B file(s), 1 media file(s), 4 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20221004_143421-cg4ma7og\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tnjpi2xr with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [64, 128, 256]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_shuffling: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 1\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\simon\\PycharmProjects\\AnalysisSearchVD\\KTH-EQ2425\\project3\\wandb\\run-20221004_143610-tnjpi2xr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/runs/tnjpi2xr\" target=\"_blank\">celestial-sweep-2</a></strong> to <a href=\"https://wandb.ai/eq2425_2022p3_aillet_bonato/project3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/sweeps/i7ytjfap\" target=\"_blank\">https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/sweeps/i7ytjfap</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - ETA: 0s - loss: 2.1172 - accuracy: 0.2441"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: c:\\Users\\simon\\PycharmProjects\\AnalysisSearchVD\\KTH-EQ2425\\project3\\wandb\\run-20221004_143610-tnjpi2xr\\files\\model-best\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: c:\\Users\\simon\\PycharmProjects\\AnalysisSearchVD\\KTH-EQ2425\\project3\\wandb\\run-20221004_143610-tnjpi2xr\\files\\model-best\\assets\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (c:\\Users\\simon\\PycharmProjects\\AnalysisSearchVD\\KTH-EQ2425\\project3\\wandb\\run-20221004_143610-tnjpi2xr\\files\\model-best)... Done. 0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 71s 90ms/step - loss: 2.1172 - accuracy: 0.2441 - val_loss: 1.8770 - val_accuracy: 0.3210\n",
            "313/313 [==============================] - 3s 8ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.0197</td></tr><tr><td>accuracy</td><td>0.24412</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.87697</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.11716</td></tr><tr><td>recall</td><td>0.321</td></tr><tr><td>val_accuracy</td><td>0.321</td></tr><tr><td>val_loss</td><td>1.87697</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">celestial-sweep-2</strong>: <a href=\"https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/runs/tnjpi2xr\" target=\"_blank\">https://wandb.ai/eq2425_2022p3_aillet_bonato/project3/runs/tnjpi2xr</a><br/>Synced 6 W&B file(s), 1 media file(s), 4 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20221004_143610-tnjpi2xr\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
          ]
        }
      ],
      "source": [
        "# start the sweep\n",
        "wandb.agent(sweep_id, sweep, count=5)\n",
        "wandb.run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('tf-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "997f2eb5bf27194238f7c2d0fafc406765e99f44a8da62f11c5168f8901f17e1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
